{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and load torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "import sys,cv2,timeit,gc\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from math import isinf\n",
    "\n",
    "from Utils.load_batch import *\n",
    "from Utils.utils import *\n",
    "from Utils.center_images import *\n",
    "from Utils.f1_score import *\n",
    "from ipywidgets import interact\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='grade3',context='paper', fscale=2.5, spines=True, gridlines='-',ticks=True, grid=True, figsize=(6, 4.5))\n",
    "plotcolor = (0, 0.6, 1.0)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import deepdish as dd\n",
    "\n",
    "data_folder = 'D:/data/HPA/all/'\n",
    "model_folder = 'D:/data/HPA/models/'\n",
    "LOSS = 'BCE'\n",
    "USE_SMALL_IMAGES = False\n",
    "USE_ALL_CHANNELS = True\n",
    "np.random.seed(100)\n",
    "\n",
    "print(\"Using GPU:\",torch.cuda.is_available())\n",
    "print(\"Using device \",torch.cuda.get_device_name(0))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filename = \"_augmented\"\n",
    "if USE_SMALL_IMAGES:\n",
    "    filename = filename + \"_small.h5\"\n",
    "else:\n",
    "    filename = filename + \".h5\"\n",
    "if USE_ALL_CHANNELS:\n",
    "    filename = \"all_channel\" + filename\n",
    "else:\n",
    "    filename = \"poi\" + filename\n",
    "\n",
    "d = dd.io.load(data_folder+filename)\n",
    "    \n",
    "X = d['filenames'] # filenames\n",
    "\n",
    "y = d['labels']\n",
    "\n",
    "idx = np.arange(y.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize (and load) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_OLD_MODEL = False\n",
    "\n",
    "#Setup resnet model\n",
    "net = models.resnet34(pretrained=True)\n",
    "\n",
    "old_weights = net.conv1.weight #remember weights even though we reinit first layer\n",
    "\n",
    "if USE_ALL_CHANNELS:     \n",
    "    net.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3,bias=False) # adapt to single channel input\n",
    "    net.conv1.weights = torch.stack([old_weights[:,0,:,:], old_weights[:,0,:,:], old_weights[:,0,:,:], old_weights[:,0,:,:]]).permute([1,0,2,3])  \n",
    "    net.requires_grad = False #freeze first layer\n",
    "else:\n",
    "    net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False) # adapt to single channel input\n",
    "    net.conv1.weights = torch.stack([old_weights[:,0,:,:]]).permute([1,0,2,3])\n",
    "    net.requires_grad = False #freeze first layer\n",
    "\n",
    "if USE_SMALL_IMAGES:\n",
    "    net.fc = nn.Linear(512, 28) #adapt last layer to allow larger input images\n",
    "else:\n",
    "    net.fc = nn.Linear(51200, 28) #adapt last layer to allow larger input images\n",
    "\n",
    "# freeze feature layers (first 3 blocks, last we leave)\n",
    "ct = 0\n",
    "for child in net.children():\n",
    "    ct += 1\n",
    "    if ct < 8:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "if LOAD_OLD_MODEL:\n",
    "    modelname = \"resnet34\"\n",
    "    if USE_ALL_CHANNELS:\n",
    "        modelname = modelname + \"_all\"\n",
    "    \n",
    "    if USE_SMALL_IMAGES:\n",
    "        modelname = modelname + \"_small\"\n",
    "    net.load_state_dict(torch.load(model_folder+modelname+\".model\"))\n",
    "\n",
    "net = net.cuda()    \n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Utils.f1_loss import *\n",
    "from Utils.f1_loss import *\n",
    "\n",
    "if LOSS == 'F1':\n",
    "    #Setup custom F1 Loss\n",
    "    criterion = F1_Loss().cuda()\n",
    "else:\n",
    "    #Setup BCE Loss and optimizer\n",
    "    weights = np.asarray(y.shape[0]/np.sum(y,axis=0))\n",
    "    for idx,weight in enumerate(weights):\n",
    "        if isinf(weight):\n",
    "            weights[idx] = y.shape[0]\n",
    "    print(\"Weights = \",weights) # we weight classes given their skewed distribution\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(weights,dtype=torch.float).cuda()).cuda()\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, net.parameters()),lr=4e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5, patience = 100, min_lr = 1e-7, verbose=True)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gc.collect() \n",
    "\n",
    "epochs = 5\n",
    "batch_size = 100\n",
    "time_per_epoch = 0\n",
    "net.train()\n",
    "\n",
    "iterations_per_epoch = np.ceil(X.shape[0] / batch_size).astype(int)\n",
    "runtime = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print_horizontal_divider()\n",
    "    print(\"Starting Epoch \", epoch)\n",
    "    print_horizontal_divider()\n",
    "    \n",
    "    running_loss,running_f1,average_targets_predicted = 0,0,0\n",
    "      \n",
    "    #reshuffle\n",
    "    idx = np.arange(y.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    y = y[idx]\n",
    "        \n",
    "    for i in range(iterations_per_epoch):\n",
    "        real_batch_size = np.minimum(batch_size,X.shape[0] - i*batch_size)\n",
    "        if real_batch_size == 0: #in case X.shape[0] is divisible by batch size this is required\n",
    "            real_batch_size = batch_size\n",
    "\n",
    "        start = timeit.default_timer() #measure time\n",
    "        \n",
    "        start_idx = i * batch_size \n",
    "        filenames = X[start_idx:start_idx+real_batch_size]\n",
    "        X_batch = load_batch(filenames,USE_ALL_CHANNELS).cuda()     \n",
    "        y_batch = torch.tensor(y[start_idx:start_idx+real_batch_size].astype(np.float32),dtype=torch.float).cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(X_batch)\n",
    "        \n",
    "        if LOSS == 'F1':\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #compute F1 scores\n",
    "        label = y_batch.cpu().detach().numpy().astype(np.bool)\n",
    "        logits = outputs.cpu().detach().numpy() > 0.5\n",
    "        average_targets_predicted = np.sum(logits) / batch_size\n",
    "        average_targets_present = np.sum(label) / batch_size\n",
    "        running_f1 += f1_score(label,logits)\n",
    "        \n",
    "        #measure runtime\n",
    "        stop = timeit.default_timer()\n",
    "        time_per_epoch = 0.5 * time_per_epoch + 0.5 * (stop-start) * iterations_per_epoch\n",
    "        runtime += (stop-start)\n",
    "        \n",
    "        #update LR if stagnating\n",
    "        scheduler.step(running_loss)\n",
    "        \n",
    "        #print performance metrics\n",
    "        if i % 5 == 0:\n",
    "            print('[epoch = (%d/%d), iteration = (%3d/%d), time = %3ds, est. time per epoch = %5ds] \\t loss = %.5f ## F1 = %.5f pred/img = %.3f / %.3f'\\\n",
    "                  %(epoch + 1, epochs,i + 1, iterations_per_epoch, runtime, time_per_epoch, running_loss / (i+1), running_f1 / (i+1), average_targets_predicted, average_targets_present))\n",
    "\n",
    "print(\"Overall done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filename = \"_6_\"\n",
    "if USE_SMALL_IMAGES:\n",
    "    filename = filename + \"small.h5\"\n",
    "else:\n",
    "    filename = filename + \".h5\"\n",
    "if USE_ALL_CHANNELS:\n",
    "    filename = \"all_channel\" + filename\n",
    "else:\n",
    "    filename = \"poi\" + filename\n",
    "\n",
    "d = dd.io.load(data_folder+filename)\n",
    "    \n",
    "Xval = center_images(d['X'].astype(np.float32) / 255.0) # torch likes float images\n",
    "yval = d['labels']\n",
    "\n",
    "idx = np.arange(yval.shape[0])\n",
    "\n",
    "np.random.shuffle(idx)\n",
    "Xval = Xval[idx]\n",
    "yval = yval[idx]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run validation\n",
    "gc.collect() \n",
    "net.eval()\n",
    "\n",
    "batch_size = 67\n",
    "iterations_per_epoch = np.ceil(Xval.shape[0] / batch_size).astype(int)\n",
    "time_per_epoch,runtime,running_loss,running_f1 = 0,0,0,0\n",
    "\n",
    "for i in range(iterations_per_epoch):\n",
    "    start = timeit.default_timer() #measure time\n",
    "\n",
    "    start_idx = i * batch_size \n",
    "    X_batch = torch.tensor(Xval[start_idx:start_idx+batch_size].transpose(0,3,1,2))\n",
    "    y_batch = torch.tensor(yval[start_idx:start_idx+batch_size].astype(np.float32),dtype=torch.float)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(X_batch)\n",
    "\n",
    "    loss = criterion(outputs, y_batch)\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "\n",
    "    #compute F1 scores\n",
    "    act = torch.sigmoid(outputs)\n",
    "\n",
    "    label = y_batch.detach().numpy().astype(np.bool)\n",
    "    logits = act.detach().numpy() > 0.5\n",
    "    print(\"Targets in batch = \",np.sum(label),\"Predicted targets = \",np.sum(logits))\n",
    "    running_f1 += f1_score(label,logits)\n",
    "\n",
    "    #measure runtime\n",
    "    stop = timeit.default_timer()\n",
    "    time_per_epoch = 0.5 * time_per_epoch + 0.5 * (stop-start) * iterations_per_epoch\n",
    "    runtime += (stop-start)\n",
    "    #print performance metrics\n",
    "    N = ((i+1)*batch_size)\n",
    "    print('[iteration = (%3d/%d), time = %3ds, est. time per epoch = %5ds] \\t loss = %.5f ## F1 = %.5f'\\\n",
    "          %(i + 1, iterations_per_epoch, runtime, time_per_epoch, running_loss / N, running_f1 / (i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "modelname = \"resnet34\"\n",
    "if USE_ALL_CHANNELS:\n",
    "    modelname = modelname + \"_all\"\n",
    "\n",
    "if USE_SMALL_IMAGES:\n",
    "    modelname = modelname + \"_small\"\n",
    "    \n",
    "if USE_SMALL_IMAGES:\n",
    "    torch.save(net.state_dict(), model_folder+modelname+\".model\")\n",
    "else:\n",
    "    torch.save(net.state_dict(),  model_folder+modelname+\".model\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown system (can be run after training and saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "cmdCommand = \"shutdown -s\"\n",
    "process = subprocess.Popen(cmdCommand.split(), stdout=subprocess.PIPE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
