{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "import sys,cv2,gc\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas\n",
    "from Utils.utils import *\n",
    "from ipywidgets import interact\n",
    "import deepdish as dd\n",
    "from skimage import io, transform\n",
    "\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "# set \"context\" (paper, notebook, talk, poster)\n",
    "jtplot.style(theme='grade3',context='talk', fscale=2.5, spines=True, gridlines='',ticks=True, grid=True, figsize=(6, 4.5))\n",
    "plotcolor = (0, 0.6, 1.0)\n",
    "\n",
    "# Load augmentation stuff\n",
    "from albumentations import (\n",
    "    IAAFliplr,IAAFlipud, OneOf, RandomContrast, RandomBrightness, RandomRotate90,\n",
    "    IAASharpen, HueSaturationValue,IAAAdditiveGaussianNoise, MedianBlur, GaussNoise,\n",
    "    IAAPiecewiseAffine, OneOf, Compose, Transpose,MotionBlur, Blur\n",
    ")\n",
    "def augment(p=1):\n",
    "    return Compose([RandomRotate90(),IAAFliplr(),IAAFlipud(),Transpose(),\n",
    "        OneOf([GaussNoise(),], p=0.25),\n",
    "        OneOf([MotionBlur(p=.2),MedianBlur(blur_limit=3, p=.1),Blur(blur_limit=3, p=.1),], p=0.25),\n",
    "        OneOf([IAASharpen(),RandomContrast(),RandomBrightness(),], p=0.5)\n",
    "    ], p=p)\n",
    "\n",
    "data_folder = 'D:/data/HPA/all/'\n",
    "target_count = 500 #set this lower than actual target count. will increase anyways\n",
    "USE_ALL_CHANNELS = True\n",
    "RESIZE = False\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Read Labels\n",
    "label_csv = pandas.read_csv(data_folder+'train.csv')\n",
    "samplecount = label_csv['Id'].size\n",
    "filenames = label_csv[\"Id\"].values\n",
    "labels = np.zeros([samplecount,28],dtype = np.bool)\n",
    "\n",
    "for i, row in label_csv.iterrows():\n",
    "    labelNr = list(map(int,row['Target'].split(' ')))\n",
    "    labels[i,labelNr] = True #Convert labels to bool, where entry is true if class is present\n",
    "    \n",
    "frequencies = labels.sum(axis=0)\n",
    "classes = np.argsort(frequencies)\n",
    "frequencies.sort()\n",
    "print(frequencies)\n",
    "\n",
    "#shuffle labels and filenames\n",
    "idx = np.arange(samplecount)\n",
    "np.random.shuffle(idx)\n",
    "filenames = filenames[idx].tolist()\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason we need to load theme twice...\n",
    "# set \"context\" (paper, notebook, talk, poster)\n",
    "jtplot.style(theme='grade3',context='talk', fscale=2.5, spines=True, gridlines='',ticks=True, grid=True, figsize=(6, 4.5))\n",
    "plotcolor = (0, 0.6, 1.0)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.bar(range(28),frequencies,width = 0.5)\n",
    "xtick_labels = list(map(str, classes))\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Class Index\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "_ = plt.xticks(range(28),xtick_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample and augment data\n",
    "We sample in two steps:\n",
    "- Get as many samples as possible or necessary from the present data\n",
    "- Augment underrepresented classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "print(\"Collecting garbage...\")\n",
    "gc.collect()\n",
    "\n",
    "X = []\n",
    "selected_labels = []\n",
    "class_representation = np.zeros(28)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1\n",
    "for classNr in classes: #Iterate over classes starting with least represented ones\n",
    "    print(\"######################## Sampling class: \", classNr, \"Current class samples = \", class_representation[classNr], '######################## ')\n",
    "    current_class_representation = class_representation[classNr]\n",
    "    \n",
    "    i = 0\n",
    "    while(True): #Iterate over files\n",
    "        #if enough samples collected for class, move on\n",
    "        if current_class_representation >= target_count:\n",
    "            break\n",
    "        #iterating over changing stuff is nasty, this is our abort.\n",
    "        if i >= len(filenames):\n",
    "            break\n",
    "            \n",
    "        #check sample contains target class\n",
    "        if labels[i][classNr]:\n",
    "            #if sample present, add to dataset \n",
    "            fn = data_folder+'train/'+filenames[i]\n",
    "            blue,green,red,yellow = cv2.imread(fn+'_blue.png',0),cv2.imread(fn+'_green.png',0),cv2.imread(fn+'_red.png',0),cv2.imread(fn+'_yellow.png',0)\n",
    "            \n",
    "            selected_labels.append(labels[i]) #store labels\n",
    "            class_representation += labels[i] #update representation\n",
    "            current_class_representation += 1\n",
    "            \n",
    "            # Store image, already handle resizing and channels\n",
    "            if USE_ALL_CHANNELS: \n",
    "                all_img = np.asarray([green,red,blue,yellow]).transpose(1,2,0)\n",
    "                if RESIZE:\n",
    "                    all_img = transform.resize(all_img.squeeze(), (224, 224), preserve_range=True)\n",
    "                X.append(all_img.astype(np.uint8))\n",
    "            else:\n",
    "                if RESIZE:\n",
    "                    green = transform.resize(green, (224, 224), preserve_range=True)\n",
    "                X.append(np.expand_dims(green,axis=2).astype(np.uint8))\n",
    "\n",
    "            #Drop this sample from remaining data\n",
    "            filenames = np.delete(filenames,i, axis=0)\n",
    "            labels = np.delete(labels, i, axis=0)\n",
    "            \n",
    "            printProgressBar (current_class_representation, target_count, prefix = 'Sampling class...', suffix = '(' + str(current_class_representation) + '/' + str(target_count) + ')')\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "print_horizontal_divider()\n",
    "print(\"Class representation after sampling: \", class_representation)\n",
    "print(\"Done.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we update the target number now, because oversampled the overrepresented classes for sure\n",
    "#we aim for the middle ground between the overpresentation (the max) and the mean representation\n",
    "# target_count = np.round((target_count + np.max(class_representation) - np.mean(class_representation)) / 2.0)\n",
    "# print(\"New target count =\", target_count)\n",
    "# print(X[0].shape)\n",
    "#store augmentations separately, we don't want to augment already augmented images\n",
    "augmentedImages = [] \n",
    "augmentedLabels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "for classNr in classes: #Iterate over classes starting with least represented ones\n",
    "    current_class_representation = class_representation[classNr]\n",
    "    i = 0\n",
    "    while current_class_representation < target_count: # iterate as long as needed to get enough samples\n",
    "        label = selected_labels[i]\n",
    "        \n",
    "        #check sample contains target class\n",
    "        if label[classNr]:\n",
    "            #augment image\n",
    "            aug = augment()\n",
    "            img = aug(image=X[i].squeeze().astype(np.uint8))['image']\n",
    "            if not USE_ALL_CHANNELS:\n",
    "                img = np.expand_dims(img,axis=2)\n",
    "#             fig = plt.figure(figsize=(10,5))\n",
    "#             f, axarr = plt.subplots(1,2)\n",
    "#             axarr[0].imshow(X[i].squeeze())\n",
    "#             axarr[1].imshow(img.squeeze())\n",
    "#             plt.show()\n",
    "#             wait\n",
    "\n",
    "            #add image\n",
    "            augmentedImages.append(img)\n",
    "            \n",
    "            #add label\n",
    "            augmentedLabels.append(label)\n",
    "            \n",
    "            #update class representation)\n",
    "            class_representation += selected_labels[i] #update representation\n",
    "            current_class_representation += 1\n",
    "            \n",
    "            if  i % 25 == 0 or (current_class_representation == target_count):\n",
    "                printProgressBar (current_class_representation, target_count, prefix = 'Augmenting class ' + str(classNr) + '...', suffix = '(' + str(current_class_representation) + '/' + str(target_count) + ')')\n",
    "            \n",
    "        i = (i + 1) % len(selected_labels)\n",
    "\n",
    "\n",
    "#add augmented images\n",
    "X.extend(augmentedImages)\n",
    "selected_labels.extend(augmentedLabels)\n",
    "\n",
    "print_horizontal_divider()\n",
    "print(\"Final class representation: \", class_representation)\n",
    "print(\"Total samples = \", len(X))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# store data\n",
    "data = {'X': np.asarray(X), 'labels': np.asarray(selected_labels)}\n",
    "if USE_ALL_CHANNELS: \n",
    "    if RESIZE:\n",
    "        dd.io.save(data_folder+'all_channel_augmented_small.h5', data,compression=('blosc', 8))\n",
    "    else:\n",
    "        dd.io.save(data_folder+'all_channel_augmented.h5', data,compression=('blosc', 8))\n",
    "else:\n",
    "    if RESIZE:\n",
    "        dd.io.save(data_folder+'poi_augmented_small.h5', data,compression=('blosc', 8))\n",
    "    else:\n",
    "        dd.io.save(data_folder+'poi_augmented.h5', data,compression=('blosc', 8))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dd.io.load(data_folder+'poi_0_small.h5')\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = d['X']\n",
    "print(X.shape)\n",
    "plt.imshow(X[42].squeeze(),cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
