{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "import sys,cv2\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from Utils.utils import *\n",
    "from Utils.f1_score import *\n",
    "from ipywidgets import interact\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "# set \"context\" (paper, notebook, talk, poster)\n",
    "jtplot.style(theme='grade3',context='talk', fscale=2.5, spines=True, gridlines='-',ticks=True, grid=True, figsize=(6, 4.5))\n",
    "plotcolor = (0, 0.6, 1.0)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import deepdish as dd\n",
    "\n",
    "import timeit,gc\n",
    "\n",
    "data_folder = 'D:/data/HPA/all/'\n",
    "model_folder = 'D:/data/HPA/models/'\n",
    "USE_SMALL_IMAGES = True\n",
    "USE_ONLY_POI = True\n",
    "\n",
    "print(\"Using GPU:\",torch.cuda.is_available())\n",
    "print(\"Using device \",torch.cuda.get_device_name(0))\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if USE_ONLY_POI:\n",
    "    filename = 'test_poi'\n",
    "else:\n",
    "    filename = 'test_all_channel_'\n",
    "    \n",
    "if USE_SMALL_IMAGES:\n",
    "    d = dd.io.load(data_folder+filename+'_small.h5')\n",
    "else:\n",
    "    d = dd.io.load(data_folder+filename+'.h5')\n",
    "\n",
    "    \n",
    "X = d['X'].astype(np.float32) / 255.0 # torch likes float images\n",
    "\n",
    "y = d['labels']\n",
    "   \n",
    "print(\"Shapes are:\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup resnet model\n",
    "net = models.resnet18(pretrained=False)\n",
    "modelname = \"baseline\"\n",
    "\n",
    "if USE_ONLY_POI:\n",
    "    net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "else:\n",
    "    net.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "    \n",
    "if USE_SMALL_IMAGES:\n",
    "    net.fc = nn.Linear(512, 28) #adapt last layer to allow larger input images\n",
    "else:\n",
    "    net.fc = nn.Linear(51200, 28) #adapt last layer to allow larger input images\n",
    "\n",
    "if USE_ONLY_POI:\n",
    "    modelname = modelname + \"_all\"\n",
    "    \n",
    "if USE_SMALL_IMAGES:\n",
    "    modelname = modelname + \"_small\"\n",
    "\n",
    "net.load_state_dict(torch.load(model_folder+modelname+\".model\")) \n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run test set (TODO remember output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "gc.collect() \n",
    "net.eval()\n",
    "\n",
    "batch_size = 67\n",
    "iterations_per_epoch = round(X.shape[0] / batch_size)\n",
    "time_per_epoch,runtime,running_loss,running_f1 = 0,0,0,0\n",
    "\n",
    "for i in range(iterations_per_epoch):\n",
    "    start = timeit.default_timer() #measure time\n",
    "\n",
    "    X_batch = torch.tensor(X[i:i+batch_size].transpose(0,3,1,2))\n",
    "    y_batch = torch.tensor(y[i:i+batch_size].astype(np.float32),dtype=torch.float)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(X_batch)\n",
    "\n",
    "    #compute F1 scores\n",
    "    act = torch.sigmoid(outputs)\n",
    "\n",
    "    label = y_batch.detach().numpy().astype(np.bool)\n",
    "    logits = act.detach().numpy() > 0.5\n",
    "    print(\"Targets in batch = \",np.sum(label),\"Predicted targets = \",np.sum(logits))\n",
    "    running_f1 += f1_score(label,logits)\n",
    "\n",
    "    #measure runtime\n",
    "    stop = timeit.default_timer()\n",
    "    time_per_epoch = 0.5 * time_per_epoch + 0.5 * (stop-start) * iterations_per_epoch\n",
    "    runtime += (stop-start)\n",
    "    #print performance metrics\n",
    "    N = ((i+1)*batch_size)\n",
    "    print('[iteration = (%3d/%d), time = %3ds, est. time per epoch = %5ds] \\t ## F1 = %.5f'\\\n",
    "          %(i + 1, iterations_per_epoch, runtime, time_per_epoch, running_f1 / (i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission.csv (TODO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
