{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup and load torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "import sys,cv2\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from Utils.utils import *\n",
    "from Utils.f1_score import *\n",
    "from ipywidgets import interact\n",
    "%matplotlib inline\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "# set \"context\" (paper, notebook, talk, poster)\n",
    "jtplot.style(theme='grade3',context='talk', fscale=2.5, spines=True, gridlines='-',ticks=True, grid=True, figsize=(6, 4.5))\n",
    "plotcolor = (0, 0.6, 1.0)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import timeit,gc\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Load training data\n",
    "import deepdish as dd\n",
    "\n",
    "data_folder = 'D:/data/HPA/all/'\n",
    "\n",
    "d = dd.io.load(data_folder+'poi_0.h5')\n",
    "X = d['X'].astype(np.float32) / 255.0 # torch likes float images\n",
    "\n",
    "y = d['labels']\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, transform\n",
    "from Utils.utils import *\n",
    "\n",
    "X_small = np.zeros((5000,224,224,1),dtype=np.float32)\n",
    "for i,img in enumerate(X):\n",
    "    if i % 25 == 0:\n",
    "        printProgressBar (i, X.shape[0], prefix = 'Resizing images...', suffix = '(' + str(i) + '/' + str(X.shape[0]) + ')')\n",
    "    X_small[i] = np.expand_dims(transform.resize(img.squeeze(), (224, 224)),axis=2)\n",
    "\n",
    "X = X_small\n",
    "    \n",
    "print(\"Shapes are:\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Models.simpleConvNet import *\n",
    "#Setup resnet model and optimizer\n",
    "\n",
    "net = models.resnet18(pretrained=False)\n",
    "# net.fc = nn.Linear(51200, 28) #adapt last layer to allow larger input images\n",
    "net.fc = nn.Linear(512, 28) #adapt last layer to allow larger input images\n",
    "net.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "\n",
    "# net = simpleConvNet()\n",
    "\n",
    "#BCE Loss\n",
    "weights = np.asarray(y.shape[0]/np.sum(y,axis=0))\n",
    "weights[15] = y.shape[0]\n",
    "print(\"Weights = \",weights) # we weight classes given their skewed distribution\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(weights,dtype=torch.float))\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.0001)\n",
    "\n",
    "print(\"Using GPU:\",torch.cuda.is_available())\n",
    "print(\"Using device \",torch.cuda.get_device_name(0))\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "gc.collect() \n",
    "\n",
    "epochs = 1\n",
    "batch_size = 50\n",
    "time_per_epoch = 0\n",
    "\n",
    "iterations_per_epoch = round(30000 / batch_size)\n",
    "runtime = 0\n",
    "partNr = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    running_f1 = 0\n",
    "    \n",
    "    current_buffer_size = X.shape[0]\n",
    "    actual_idx = 0\n",
    "    for i in range(iterations_per_epoch):\n",
    "        if actual_idx*batch_size > y.shape[0]:\n",
    "            print(\"Loading data part \" + str(partNr))\n",
    "            d = dd.io.load(data_folder+'poi_'+str(partNr)+'.h5')\n",
    "            X = d['X'].astype(np.float32) / 255.0 # torch likes float images\n",
    "            y = d['labels']\n",
    "            \n",
    "            X_small = np.zeros((X.shape[0],224,224,1),dtype=np.float32)\n",
    "            for i,img in enumerate(X):\n",
    "                if i % 25 == 0:\n",
    "                    printProgressBar (i, X.shape[0], prefix = 'Resizing images...', suffix = '(' + str(i) + '/' + str(X.shape[0]) + ')')\n",
    "                X_small[i] = np.expand_dims(transform.resize(img.squeeze(), (224, 224)),axis=2)\n",
    "\n",
    "            X = X_small\n",
    "            \n",
    "            actual_idx = 0\n",
    "            partNr += 1\n",
    "            print(\"Done.\")\n",
    "        \n",
    "        start = timeit.default_timer() #measure time\n",
    "        \n",
    "        X_batch = torch.tensor(X[actual_idx:actual_idx+batch_size].transpose(0,3,1,2))\n",
    "        y_batch = torch.tensor(y[actual_idx:actual_idx+batch_size].astype(np.float32),dtype=torch.float)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(X_batch)\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #compute F1 scores\n",
    "        act = torch.sigmoid(outputs)\n",
    "        \n",
    "        label = y_batch.detach().numpy().astype(np.bool)\n",
    "        logits = act.detach().numpy() > 0.5\n",
    "        print(\"Targets in batch = \",np.sum(label),\"Predicted targets = \",np.sum(logits))\n",
    "        running_f1 += f1_score(label,logits)\n",
    "        \n",
    "        #measure runtime\n",
    "        stop = timeit.default_timer()\n",
    "        time_per_epoch = 0.5 * time_per_epoch + 0.5 * (stop-start) * iterations_per_epoch\n",
    "        runtime += (stop-start)\n",
    "        #print performance metrics\n",
    "        N = ((i+1)*batch_size)\n",
    "        print('[epoch = (%d/%d), iteration = (%3d/%d), time = %3ds, est. time per epoch = %5ds] \\t loss = %.5f ## F1 = %.5f'\\\n",
    "              %(epoch + 1, epochs,i + 1, iterations_per_epoch, runtime, time_per_epoch, running_loss / N, running_f1 / (i+1)))\n",
    "        \n",
    "        actual_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Load validation data\n",
    "d = dd.io.load(data_folder+'poi_6.h5')\n",
    "Xval = d['X'].astype(np.float32) / 255.0 # torch likes float images\n",
    "yval = d['labels']\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xval_small = np.zeros((Xval.shape[0],224,224,1),dtype=np.float32)\n",
    "for i,img in enumerate(Xval):\n",
    "    if i % 25 == 0:\n",
    "        printProgressBar (i, X.shape[0], prefix = 'Resizing images...', suffix = '(' + str(i) + '/' + str(Xval.shape[0]) + ')')\n",
    "    Xval_small[i] = np.expand_dims(transform.resize(img.squeeze(), (224, 224)),axis=2)\n",
    "\n",
    "Xval = Xval_small\n",
    "    \n",
    "print(\"Shapes are:\")\n",
    "print(Xval.shape)\n",
    "print(yval.shape)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "gc.collect() \n",
    "\n",
    "batch_size = 67\n",
    "time_per_epoch = 0\n",
    "iterations_per_epoch = round(Xval.shape[0] / batch_size)\n",
    "runtime = 0\n",
    "running_loss = 0\n",
    "running_f1 = 0\n",
    "\n",
    "for i in range(iterations_per_epoch):\n",
    "    start = timeit.default_timer() #measure time\n",
    "\n",
    "    X_batch = torch.tensor(Xval[i:i+batch_size].transpose(0,3,1,2))\n",
    "    y_batch = torch.tensor(yval[i:i+batch_size].astype(np.float32),dtype=torch.float)\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(X_batch)\n",
    "\n",
    "    loss = criterion(outputs, y_batch)\n",
    "    \n",
    "    running_loss += loss.item()\n",
    "\n",
    "    #compute F1 scores\n",
    "    act = torch.sigmoid(outputs)\n",
    "\n",
    "    label = y_batch.detach().numpy().astype(np.bool)\n",
    "    logits = act.detach().numpy() > 0.5\n",
    "    print(\"Targets in batch = \",np.sum(label),\"Predicted targets = \",np.sum(logits))\n",
    "    running_f1 += f1_score(label,logits)\n",
    "\n",
    "    #measure runtime\n",
    "    stop = timeit.default_timer()\n",
    "    time_per_epoch = 0.5 * time_per_epoch + 0.5 * (stop-start) * iterations_per_epoch\n",
    "    runtime += (stop-start)\n",
    "    #print performance metrics\n",
    "    N = ((i+1)*batch_size)\n",
    "    print('[epoch = (%d/%d), iteration = (%3d/%d), time = %3ds, est. time per epoch = %5ds] \\t loss = %.5f ## F1 = %.5f'\\\n",
    "          %(epoch + 1, epochs,i + 1, iterations_per_epoch, runtime, time_per_epoch, running_loss / N, running_f1 / (i+1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
